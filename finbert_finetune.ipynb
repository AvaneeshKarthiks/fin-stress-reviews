{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8c46cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m117 packages\u001b[0m \u001b[2min 3.03s\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m torch \u001b[2m(104.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pyarrow \u001b[2m(26.7MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m networkx \u001b[2m(1.9MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m setuptools \u001b[2m(1.1MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m tokenizers \u001b[2m(2.6MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m sympy \u001b[2m(6.0MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m transformers \u001b[2m(11.4MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m setuptools\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m networkx\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m tokenizers\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m sympy\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m transformers\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pyarrow\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m torch\n",
      "\u001b[2mPrepared \u001b[1m46 packages\u001b[0m \u001b[2min 42.64s\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m47 packages\u001b[0m \u001b[2min 5.55s\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohappyeyeballs\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.13.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbleach\u001b[0m\u001b[2m==6.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mevaluate\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastjsonschema\u001b[0m\u001b[2m==2.21.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfrozenlist\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema\u001b[0m\u001b[2m==4.25.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema-specifications\u001b[0m\u001b[2m==2025.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkaggle\u001b[0m\u001b[2m==1.7.4.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultidict\u001b[0m\u001b[2m==6.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.16\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnbformat\u001b[0m\u001b[2m==5.10.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpropcache\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==22.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-slugify\u001b[0m\u001b[2m==8.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mreferencing\u001b[0m\u001b[2m==0.37.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrpds-py\u001b[0m\u001b[2m==0.28.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtext-unidecode\u001b[0m\u001b[2m==1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.15.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebencodings\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mxxhash\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1myarl\u001b[0m\u001b[2m==1.22.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add transformers datasets evaluate accelerate scikit-learn kaggle nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca296f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m53 packages\u001b[0m \u001b[2min 1.12s\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m scipy \u001b[2m(36.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m scikit-learn \u001b[2m(8.3MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m scikit-learn\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m scipy\n",
      "\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 10.62s\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 719ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1313a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download the Kaggle dataset (requires kaggle.json API token)\n",
    "# If you already have the CSV, skip this download step and set `local_csv_path` accordingly.\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "local_csv_path = 'data.csv'\n",
    "\n",
    "print('Using:', local_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b8f6b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: data.csv\n",
      "Shape: (5842, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shell's $70 Billion BG Deal Meets Shareholder ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kone 's net sales rose by some 14 % year-on-ye...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Stockmann department store will have a tot...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral\n",
       "5    $SPY wouldn't be surprised to see a green close  positive\n",
       "6  Shell's $70 Billion BG Deal Meets Shareholder ...  negative\n",
       "7  SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...  negative\n",
       "8  Kone 's net sales rose by some 14 % year-on-ye...  positive\n",
       "9  The Stockmann department store will have a tot...   neutral"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns: ['Sentence', 'Sentiment']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Quick peek at the dataset\n",
    "import pandas as pd\n",
    "print('Reading:', local_csv_path)\n",
    "df = pd.read_csv(local_csv_path)\n",
    "print('Shape:', df.shape)\n",
    "display(df.head(10))\n",
    "print('\\nColumns:', df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4b17dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = getattr(model.config, \"id2label\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ade4243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'positive', 1: 'negative', 2: 'neutral'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d32c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text columns candidates: ['Sentence']\n",
      "Label columns candidates: ['Sentiment']\n",
      "Using text column: Sentence and label column: Sentiment\n",
      "After normalization, label distribution:\n",
      "label\n",
      "2    3130\n",
      "0    1852\n",
      "1     860\n",
      "Name: count, dtype: int64\n",
      "Sizes -> train: 4672 val: 585 test: 585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "text_cols = ['Sentence']\n",
    "label_cols = ['Sentiment']\n",
    "\n",
    "print('Text columns candidates:', text_cols)\n",
    "print('Label columns candidates:', label_cols)\n",
    "\n",
    "if len(text_cols) == 0:\n",
    "    raise ValueError('No text-like column detected. Inspect df.columns and update the notebook to select the correct column.')\n",
    "if len(label_cols) == 0:\n",
    "    label_cols = [c for c in df.columns if c.lower() in ('polarity','sent','sentiment','label')]\n",
    "\n",
    "text_col = text_cols[0]\n",
    "label_col = label_cols[0]\n",
    "\n",
    "print('Using text column:', text_col, 'and label column:', label_col)\n",
    "\n",
    "def normalize_label(x):\n",
    "    if isinstance(x, str):\n",
    "        s = x.lower().strip()\n",
    "        if s in ('negative','neg','-1'): return 1\n",
    "        if s in ('neutral','neut','0'): return 2\n",
    "        if s in ('positive','pos','1'): return 0\n",
    "    try:\n",
    "        xi = int(x)\n",
    "        if xi == -1: return 0\n",
    "        if xi == 0: return 1\n",
    "        if xi == 1: return 2\n",
    "    except:\n",
    "        pass\n",
    "    return 1\n",
    "\n",
    "df['label'] = df[label_col].apply(normalize_label)\n",
    "df = df.rename(columns={text_col: 'text'})\n",
    "print('After normalization, label distribution:')\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "trainval, test = train_test_split(df, test_size=0.10, stratify=df['label'], random_state=42)\n",
    "train, val = train_test_split(trainval, test_size=0.1111, stratify=trainval['label'], random_state=42)  # ~0.10 of total\n",
    "print('Sizes -> train:', len(train), 'val:', len(val), 'test:', len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d804bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add transformers datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee1ad91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'Sentiment', 'label'],\n",
      "        num_rows: 4672\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'Sentiment', 'label'],\n",
      "        num_rows: 585\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'Sentiment', 'label'],\n",
      "        num_rows: 585\n",
      "    })\n",
      "})\n",
      "{'text': 'Mr. Koistinen joins from Nokia Siemens Networks where he has held various senior sales management and business development positions since 1997 .', 'Sentiment': 'neutral', 'label': 2}\n",
      "Tokenizer loaded for ProsusAI/finbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4672/4672 [00:00<00:00, 16284.46 examples/s]\n",
      "Map: 100%|██████████| 585/585 [00:00<00:00, 16652.87 examples/s]\n",
      "Map: 100%|██████████| 585/585 [00:00<00:00, 17093.73 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "train_ds = Dataset.from_pandas(train.reset_index(drop=True))\n",
    "val_ds = Dataset.from_pandas(val.reset_index(drop=True))\n",
    "test_ds = Dataset.from_pandas(test.reset_index(drop=True))\n",
    "dataset = DatasetDict({'train': train_ds, 'validation': val_ds, 'test': test_ds})\n",
    "\n",
    "print(dataset)\n",
    "print(dataset['train'][0])\n",
    "\n",
    "model_name = 'ProsusAI/finbert'\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print('Tokenizer loaded for', model_name)\n",
    "\n",
    "def preprocess_fn(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "tokenized = dataset.map(preprocess_fn, batched=True)\n",
    "tokenized = tokenized.remove_columns(['text', 'index', 'label'] if 'index' in tokenized['train'].column_names else ['text'])\n",
    "tokenized = tokenized.rename_column('label', 'labels') if 'labels' not in tokenized['train'].column_names else tokenized\n",
    "tokenized.set_format('torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a82e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained pipeline (this downloads the HF model & tokenizer).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions (pretrained finbert) on 585 examples...\n",
      "Pretrained model metrics:\n",
      "Accuracy: 0.7367521367521368\n",
      "Precision: 0.7718479166161285 Recall: 0.7367521367521368 F1: 0.7459446922158657\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.72      0.80       186\n",
      "         neu       0.47      0.77      0.58        86\n",
      "         pos       0.79      0.74      0.76       313\n",
      "\n",
      "    accuracy                           0.74       585\n",
      "   macro avg       0.71      0.74      0.71       585\n",
      "weighted avg       0.77      0.74      0.75       585\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[134   8  44]\n",
      " [  1  66  19]\n",
      " [ 16  66 231]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "\n",
    "print('Loading pretrained pipeline (this downloads the HF model & tokenizer).')\n",
    "pipe = pipeline('text-classification', model=model_name, tokenizer=model_name, return_all_scores=True, device=0)\n",
    "\n",
    "label_map = {'negative':1, 'neutral':2, 'positive':0}\n",
    "\n",
    "def hf_predict(texts, batch_size=64):\n",
    "    preds = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        outs = pipe(batch)\n",
    "        for o in outs:\n",
    "            best = max(o, key=lambda x: x['score'])\n",
    "            lbl = best['label'].lower()\n",
    "            preds.append(label_map.get(lbl, 1))\n",
    "    return preds\n",
    "\n",
    "test_texts = test['text'].tolist()\n",
    "y_true = test['label'].tolist()\n",
    "print('Running predictions (pretrained finbert) on', len(test_texts), 'examples...')\n",
    "y_pred_pre = hf_predict(test_texts)\n",
    "\n",
    "print('Pretrained model metrics:')\n",
    "acc = accuracy_score(y_true, y_pred_pre)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred_pre, average='weighted', zero_division=0)\n",
    "print('Accuracy:', acc)\n",
    "print('Precision:', prec, 'Recall:', rec, 'F1:', f1)\n",
    "print('\\nClassification report:\\n', classification_report(y_true, y_pred_pre, target_names=['neg','neu','pos']))\n",
    "print('\\nConfusion matrix:\\n', confusion_matrix(y_true, y_pred_pre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b681197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from evaluate) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from evaluate) (0.33.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (2024.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avane\\onedrive\\desktop\\coding\\dbms\\retail_banking_system\\backend\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Using cached evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d05ce6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\avane\\OneDrive\\Desktop\\coding\\DBMS\\retail_banking_system\\backend\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "num_labels = 3\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cae651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): True\n",
      "GPU count: 1\n",
      "Current device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avane\\AppData\\Local\\Temp\\ipykernel_19072\\218703820.py:59: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training... (will use GPU if available)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1460' max='1460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1460/1460 25:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.384200</td>\n",
       "      <td>0.487517</td>\n",
       "      <td>0.782906</td>\n",
       "      <td>0.785281</td>\n",
       "      <td>0.813833</td>\n",
       "      <td>0.782906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.286500</td>\n",
       "      <td>0.410227</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.820998</td>\n",
       "      <td>0.838706</td>\n",
       "      <td>0.815385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.465082</td>\n",
       "      <td>0.801709</td>\n",
       "      <td>0.796808</td>\n",
       "      <td>0.793776</td>\n",
       "      <td>0.801709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.527488</td>\n",
       "      <td>0.805128</td>\n",
       "      <td>0.793392</td>\n",
       "      <td>0.788447</td>\n",
       "      <td>0.805128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.519556</td>\n",
       "      <td>0.798291</td>\n",
       "      <td>0.792597</td>\n",
       "      <td>0.788533</td>\n",
       "      <td>0.798291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU count:\", torch.cuda.device_count())\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "\n",
    "device_id = 0 if torch.cuda.is_available() else -1  \n",
    "\n",
    "num_labels = 3\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "if torch.cuda.is_available():\n",
    "    model.to(torch.device(f\"cuda:{device_id}\"))\n",
    "\n",
    "metric_acc = evaluate.load('accuracy')\n",
    "metric_f1 = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = metric_acc.compute(predictions=preds, references=labels)['accuracy']\n",
    "    f1 = metric_f1.compute(predictions=preds, references=labels, average='weighted')['f1']\n",
    "    prec, rec, f1s, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': prec, 'recall': rec}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='finetuned-finbert-output',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,   \n",
    "    per_device_eval_batch_size=32,   \n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    fp16=True if torch.cuda.is_available() else False,  \n",
    "    logging_steps=50,\n",
    "    dataloader_num_workers=4,         \n",
    "    gradient_accumulation_steps=1   \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized['train'],\n",
    "    eval_dataset=tokenized['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print('Starting training... (will use GPU if available)')\n",
    "trainer.train()\n",
    "print('Training completed.')\n",
    "# Move model back to CPU for safe saving if needed\n",
    "model.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8716a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fine-tuned model on tokenized test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics (HF Trainer): {'eval_loss': 0.359531432390213, 'eval_accuracy': 0.8136752136752137, 'eval_f1': 0.823713687061814, 'eval_precision': 0.8503595485308112, 'eval_recall': 0.8136752136752137, 'eval_runtime': 33.852, 'eval_samples_per_second': 17.281, 'eval_steps_per_second': 0.561, 'epoch': 5.0}\n",
      "\n",
      "Fine-tuned model classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.91      0.89      0.90       186\n",
      "         neu       0.50      0.80      0.62        86\n",
      "         pos       0.91      0.77      0.84       313\n",
      "\n",
      "    accuracy                           0.81       585\n",
      "   macro avg       0.77      0.82      0.78       585\n",
      "weighted avg       0.85      0.81      0.82       585\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[165  10  11]\n",
      " [  5  69  12]\n",
      " [ 12  59 242]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "tokenized.set_format(type='torch', device=device)\n",
    "\n",
    "trainer.model.to(device)\n",
    "\n",
    "print('Evaluating fine-tuned model on tokenized test set...')\n",
    "metrics = trainer.evaluate(eval_dataset=tokenized['test'])\n",
    "print('Eval metrics (HF Trainer):', metrics)\n",
    "\n",
    "preds_output = trainer.predict(tokenized['test'])\n",
    "preds = np.argmax(preds_output.predictions, axis=-1)\n",
    "y_true = test['label'].tolist()\n",
    "\n",
    "print('\\nFine-tuned model classification report:')\n",
    "print(classification_report(y_true, preds, target_names=['neg','neu','pos']))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('\\nConfusion matrix:\\n', confusion_matrix(y_true, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e5675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('finetuned-finbert\\\\tokenizer_config.json',\n",
       " 'finetuned-finbert\\\\special_tokens_map.json',\n",
       " 'finetuned-finbert\\\\vocab.txt',\n",
       " 'finetuned-finbert\\\\added_tokens.json',\n",
       " 'finetuned-finbert\\\\tokenizer.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimal: authenticate then push saved finetuned directory\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "repo_id = \"Avaneeshkarthik/finbert-finetuned\"\n",
    "trainer.save_model(\"finetuned-finbert\")\n",
    "tokenizer.save_pretrained(\"finetuned-finbert\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
