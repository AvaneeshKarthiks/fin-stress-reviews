{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30a4454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinRAD: using text column: terms\n",
      "Extracted 500 tokens from FinRAD (top 500)\n",
      "Merged whitelist size: 542\n",
      "                                              review  finance_flag  \\\n",
      "0   Bought 100 shares of RELIANCE at ‚Çπ2,345.50 today          True   \n",
      "1        App crashes when placing order - please fix          True   \n",
      "2               Great UI, love the new color scheme!         False   \n",
      "3  SIP failed this month and I am worried about m...          True   \n",
      "4               Login issue, can't access my account          True   \n",
      "5  Sold all my holdings after panic sell, huge lo...          True   \n",
      "6  Brokerage fee seems high compared to other pla...          True   \n",
      "7                 Why is the KYC pending for 2 days?         False   \n",
      "\n",
      "   is_keyword  is_regex matched_keyword_snippet      matched_regexes  \\\n",
      "0        True      True                  shares  rupee_symbol_amount   \n",
      "1        True     False                   order                        \n",
      "2       False     False                                                \n",
      "3        True     False                     SIP                        \n",
      "4        True     False                   issue                        \n",
      "5        True      True                     all        percent_value   \n",
      "6        True     False               Brokerage                        \n",
      "7       False     False                                                \n",
      "\n",
      "                  reason  \n",
      "0         keyword:shares  \n",
      "1          keyword:order  \n",
      "2  no_match_or_too_short  \n",
      "3            keyword:SIP  \n",
      "4          keyword:issue  \n",
      "5            keyword:all  \n",
      "6      keyword:Brokerage  \n",
      "7  no_match_or_too_short  \n",
      "Saved merged whitelist to merged_finance_whitelist.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Filter reviews using:\n",
    "  1) Keyword whitelist (merged from FinRAD frequent tokens + a curated common-finance word set)\n",
    "  2) Regex patterns that capture currency, percent, tickers, order ids, shorthand like \"@ 450\"\n",
    "\n",
    "Run: pip install pandas requests nltk\n",
    "\"\"\"\n",
    "\n",
    "import io\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from typing import List, Set\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "# Raw file (raw.githubusercontent URL). If this fails for you, download manually from the GitHub page:\n",
    "# https://github.com/sohomghosh/FinRAD_Financial_Readability_Assessment_Dataset/blob/main/data_sample_1500.csv\n",
    "FINRAD_RAW_URL = \"https://raw.githubusercontent.com/sohomghosh/FinRAD_Financial_Readability_Assessment_Dataset/main/data_sample_1500.csv\"\n",
    "finrad_local_path = None  # e.g., \"/path/to/data_sample_1500.csv\" to use a local copy instead of downloading\n",
    "\n",
    "TOP_K_FINRAD_TOKENS = 500   # how many top tokens to extract from FinRAD as candidate finance words\n",
    "MIN_TOKEN_LENGTH = 3        # ignore very short tokens\n",
    "MIN_REVIEW_LEN = 10         # minimum characters for a review to be considered\n",
    "# ------------------------------\n",
    "\n",
    "# ---------- Common curated financial words (compact set you can expand) ----------\n",
    "# This is a small curated \"common financial words\" set to combine with FinRAD-derived tokens.\n",
    "COMMON_FIN_WORDS = {\n",
    "    \"buy\", \"sell\", \"trade\", \"order\", \"limit order\", \"market order\", \"stop loss\",\n",
    "    \"margin\", \"margin call\", \"intraday\", \"swing\", \"long\", \"short\",\n",
    "    \"stock\", \"share\", \"equity\", \"futures\", \"options\", \"mutual fund\", \"sip\", \"ipo\", \"etf\",\n",
    "    \"bond\", \"derivative\", \"portfolio\", \"broker\", \"brokerage\", \"commission\", \"fee\", \"tax\",\n",
    "    \"dividend\", \"profit\", \"loss\", \"pnl\", \"realized\", \"unrealized\", \"nse\", \"bse\", \"nifty\",\n",
    "    \"sensex\", \"ipo allotment\", \"ltp\", \"tick\", \"volume\", \"order id\", \"txn\", \"transaction\",\n",
    "    \"settlement\", \"upi\", \"bank\", \"demat\", \"dp\", \"scrip\", \"circuit breaker\", \"selloff\",\n",
    "    \"panic\", \"panic-sell\", \"withdraw\", \"deposit\", \"portfolio value\", \"exit\", \"entry\",\n",
    "    \"brokerage\", \"tax-loss\", \"tax harvesting\"\n",
    "}\n",
    "\n",
    "# ---------- regex patterns ----------\n",
    "REGEX_PATTERNS = {\n",
    "    \"percent_value\": re.compile(r\"\\b\\d{1,3}(?:[.,]\\d+)?\\s?%\"),                        # 5% / 10.5 %\n",
    "    \"rupee_symbol_amount\": re.compile(r\"‚Çπ\\s?\\d[\\d,]*(?:\\.\\d+)?\"),                    # ‚Çπ1,234.56\n",
    "    \"rs_amount\": re.compile(r\"\\b(?:rs\\.?|inr)\\s?\\d[\\d,]*(?:\\.\\d+)?\\b\", re.I),         # rs 1200 / INR1200\n",
    "    \"exchange_tag\": re.compile(r\"\\b(?:NSE|BSE|NIFTY|SENSEX)\\b\", re.I),\n",
    "    \"order_txn\": re.compile(r\"\\b(?:order id|order#|ordernumber|txn id|transaction id|txnid)\\b\", re.I),\n",
    "    \"stop_loss_phrase\": re.compile(r\"\\bstop[- ]?loss\\b\", re.I),\n",
    "    \"margin_call_phrase\": re.compile(r\"\\bmargin call\\b\", re.I),\n",
    "    \"at_price_shorthand\": re.compile(r\"[@]\\s?\\d[\\d,]*(?:\\.\\d+)?\"),                    # '@ 450' or '@450'\n",
    "    \"percent_word\": re.compile(r\"\\bpercent\\b|\\bpercentage\\b\", re.I),\n",
    "    \"price_word\": re.compile(r\"\\bprice\\b|\\bclosing price\\b|\\bopen price\\b\", re.I),\n",
    "}\n",
    "\n",
    "# ---------- helper functions ----------\n",
    "def download_finrad_csv(raw_url: str) -> bytes:\n",
    "    \"\"\"Download the CSV bytes from the raw GitHub URL. If it fails, raise an exception.\"\"\"\n",
    "    headers = {\"User-Agent\": \"python-requests/2.x\"}\n",
    "    r = requests.get(raw_url, headers=headers, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.content\n",
    "\n",
    "def load_finrad_df(raw_bytes: bytes) -> pd.DataFrame:\n",
    "    \"\"\"Load csv bytes into a pandas DataFrame.\"\"\"\n",
    "    return pd.read_csv(io.BytesIO(raw_bytes), encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "def choose_text_column(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Heuristic to pick the most likely text column in FinRAD sample:\n",
    "    prefer columns named 'text', 'sentence', 'content', otherwise choose the string column\n",
    "    with largest average length.\n",
    "    \"\"\"\n",
    "    preferred = [c for c in df.columns if c.lower() in {\"text\", \"sentence\", \"content\", \"sample\", \"excerpt\"}]\n",
    "    if preferred:\n",
    "        return preferred[0]\n",
    "    # fallback: pick object dtype column with largest average length\n",
    "    obj_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
    "    if not obj_cols:\n",
    "        # as fallback, use first column\n",
    "        return df.columns[0]\n",
    "    avg_lens = {c: df[c].astype(str).str.len().mean() for c in obj_cols}\n",
    "    # return column with max avg len\n",
    "    return max(avg_lens, key=avg_lens.get)\n",
    "\n",
    "def extract_top_tokens_from_texts(texts: List[str], top_k=500, min_len=3, stopwords: Set[str]=None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Tokenize texts, count token frequency, and return top_k tokens (lowercased).\n",
    "    Very conservative tokenization: keeps alphabetic tokens.\n",
    "    \"\"\"\n",
    "    token_re = re.compile(r\"\\b[a-zA-Z]{%d,}\\b\" % min_len)\n",
    "    counter = Counter()\n",
    "    for t in texts:\n",
    "        if not isinstance(t, str):\n",
    "            continue\n",
    "        for m in token_re.findall(t):\n",
    "            token = m.lower()\n",
    "            if stopwords and token in stopwords:\n",
    "                continue\n",
    "            counter[token] += 1\n",
    "    most = [tok for tok, _ in counter.most_common(top_k)]\n",
    "    return most\n",
    "\n",
    "def compile_keyword_regex(words: List[str]) -> re.Pattern:\n",
    "    \"\"\"\n",
    "    Build a case-insensitive regex that will match any phrase in words.\n",
    "    Long phrases are placed earlier to ensure greedy matching.\n",
    "    \"\"\"\n",
    "    # Escape and sort by length to match multi-word phrases first\n",
    "    escaped = [re.escape(w) for w in sorted(set(words), key=len, reverse=True) if w.strip()]\n",
    "    # join using a non-capturing group; use word boundaries to reduce false positives\n",
    "    pattern = r\"\\b(?:\" + \"|\".join(escaped) + r\")\\b\"\n",
    "    return re.compile(pattern, re.I)\n",
    "\n",
    "def filter_reviews_by_whitelist_and_regex(\n",
    "    reviews_df: pd.DataFrame,\n",
    "    text_col: str,\n",
    "    keyword_pattern: re.Pattern,\n",
    "    regex_patterns: dict,\n",
    "    min_len: int = 10\n",
    ") -> pd.DataFrame:\n",
    "    s = reviews_df[text_col].astype(str).fillna(\"\").str.strip()\n",
    "    length_ok = s.str.len() >= min_len\n",
    "    is_keyword = s.str.contains(keyword_pattern, na=False)\n",
    "\n",
    "    matched_any_regex = pd.Series(False, index=reviews_df.index)\n",
    "    matched_regex_keys = [[] for _ in range(len(reviews_df))]\n",
    "    for key, pat in regex_patterns.items():\n",
    "        found = s.str.contains(pat, na=False)\n",
    "        matched_any_regex = matched_any_regex | found\n",
    "        for idx in reviews_df.index[found]:\n",
    "            matched_regex_keys[idx] = matched_regex_keys[idx] + [key]\n",
    "\n",
    "    out = reviews_df.copy()\n",
    "    out[\"text_len\"] = s.str.len()\n",
    "    out[\"is_keyword\"] = is_keyword\n",
    "    out[\"is_regex\"] = matched_any_regex\n",
    "    out[\"matched_regexes\"] = [\",\".join(keys) if keys else \"\" for keys in matched_regex_keys]\n",
    "    # first keyword match snippet\n",
    "    def first_keyword_match(txt: str):\n",
    "        m = keyword_pattern.search(txt)\n",
    "        return m.group(0) if m else \"\"\n",
    "    out[\"matched_keyword_snippet\"] = s.apply(first_keyword_match)\n",
    "    out[\"finance_flag\"] = (out[\"is_keyword\"] | out[\"is_regex\"]) & length_ok\n",
    "\n",
    "    def reason_row(r):\n",
    "        if not r[\"finance_flag\"]:\n",
    "            return \"no_match_or_too_short\"\n",
    "        if r[\"is_keyword\"]:\n",
    "            return f\"keyword:{r['matched_keyword_snippet'] or 'match'}\"\n",
    "        if r[\"is_regex\"]:\n",
    "            return f\"regex:{r['matched_regexes']}\"\n",
    "        return \"matched\"\n",
    "    out[\"reason\"] = out.apply(reason_row, axis=1)\n",
    "    return out\n",
    "\n",
    "# ---------- Main pipeline ----------\n",
    "def build_and_apply_filter(reviews_df: pd.DataFrame, review_text_col: str = \"review\"):\n",
    "    # 1) load FinRAD tokens\n",
    "    finrad_texts = []\n",
    "    try:\n",
    "        if finrad_local_path:\n",
    "            with open(finrad_local_path, \"rb\") as f:\n",
    "                raw = f.read()\n",
    "        else:\n",
    "            raw = download_finrad_csv(FINRAD_RAW_URL)\n",
    "        df_finrad = load_finrad_df(raw)\n",
    "        text_col = \"terms\"\n",
    "        print(\"FinRAD: using text column:\", text_col)\n",
    "        finrad_texts = df_finrad[text_col].astype(str).tolist()\n",
    "    except Exception as e:\n",
    "        print(\"Could not load FinRAD CSV automatically:\", e)\n",
    "        finrad_texts = []\n",
    "\n",
    "    # 2) compute top tokens from FinRAD (if available)\n",
    "    stopwords = set()\n",
    "    try:\n",
    "        import nltk\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "        from nltk.corpus import stopwords as sw\n",
    "        stopwords = set(sw.words('english'))\n",
    "    except Exception:\n",
    "        # if nltk not available, use a small default stopwords set\n",
    "        stopwords = {\"the\", \"and\", \"for\", \"with\", \"that\", \"this\", \"are\", \"was\", \"from\", \"have\", \"has\"}\n",
    "\n",
    "    fin_tokens = []\n",
    "    if finrad_texts:\n",
    "        fin_tokens = extract_top_tokens_from_texts(finrad_texts, top_k=TOP_K_FINRAD_TOKENS, min_len=MIN_TOKEN_LENGTH, stopwords=stopwords)\n",
    "        print(f\"Extracted {len(fin_tokens)} tokens from FinRAD (top {TOP_K_FINRAD_TOKENS})\")\n",
    "    else:\n",
    "        print(\"No FinRAD texts available; skipping FinRAD-derived tokens.\")\n",
    "\n",
    "    # 3) Merge curated common list + finrad tokens\n",
    "    merged = set([w.lower() for w in COMMON_FIN_WORDS])\n",
    "    merged.update(fin_tokens)\n",
    "    merged_list = sorted(merged)\n",
    "    print(\"Merged whitelist size:\", len(merged_list))\n",
    "\n",
    "    # 4) compile keyword regex\n",
    "    keyword_re = compile_keyword_regex(merged_list)\n",
    "\n",
    "    # 5) apply filter to user's reviews DataFrame\n",
    "    filtered = filter_reviews_by_whitelist_and_regex(reviews_df, text_col=review_text_col, keyword_pattern=keyword_re, regex_patterns=REGEX_PATTERNS, min_len=MIN_REVIEW_LEN)\n",
    "    return filtered, merged_list\n",
    "\n",
    "# ---------- Example usage ----------\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample reviews DF (replace with your Zerodha reviews DataFrame)\n",
    "    sample_reviews = [\n",
    "        \"Bought 100 shares of RELIANCE at ‚Çπ2,345.50 today\",\n",
    "        \"App crashes when placing order - please fix\",\n",
    "        \"Great UI, love the new color scheme!\",\n",
    "        \"SIP failed this month and I am worried about my investments\",\n",
    "        \"Login issue, can't access my account\",\n",
    "        \"Sold all my holdings after panic sell, huge loss of 12%\",\n",
    "        \"Brokerage fee seems high compared to other platforms\",\n",
    "        \"Why is the KYC pending for 2 days?\"\n",
    "    ]\n",
    "    reviews_df = pd.DataFrame({\"review\": sample_reviews})\n",
    "    filtered_df, whitelist = build_and_apply_filter(reviews_df, review_text_col=\"review\")\n",
    "\n",
    "    print(filtered_df[[\"review\", \"finance_flag\", \"is_keyword\", \"is_regex\", \"matched_keyword_snippet\", \"matched_regexes\", \"reason\"]])\n",
    "    # optionally save the whitelist\n",
    "    pd.Series(whitelist).to_csv(\"merged_finance_whitelist.csv\", index=False, header=False)\n",
    "    print(\"Saved merged whitelist to merged_finance_whitelist.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd0c95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'binance_reviews_last5y.csv' with 323457 rows and columns: ['reviewId', 'content', 'score', 'at', 'userName', 'thumbsUpCount', 'appVersion']\n",
      "Extracted 500 tokens from FinRAD (top 500).\n",
      "Merged whitelist size: 543 (including curated common words and FinRAD-derived tokens)\n",
      "Filtered dataset saved to: binance_reviews_last5y_filtered.csv\n",
      "Total rows: 323457, Finance-related rows kept: 103325 (31.94%)\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           content  finance_flag  is_keyword  is_regex matched_keyword_snippet matched_regexes             reason\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Its really good app          True        True     False                    good                       keyword:good\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             good app for exchange          True        True     False                    good                       keyword:good\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    good to have my account back üëç          True        True     False                    good                       keyword:good\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                           nice and better for regulatory platform          True        True     False              regulatory                 keyword:regulatory\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                the best exchanger of the world üåçüåé          True        True     False                   world                      keyword:world\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                         Binance is good app for me. i am very proud of this appüòçü•∞          True        True     False                    good                       keyword:good\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      maybe good üíØ          True        True     False                    good                       keyword:good\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                        cat timp sa astept for review the document . prima ora stop pentru poza. a doua ora astept pentru review .          True        True     False                    stop                       keyword:stop\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     word number one platform ‚ù§Ô∏è‚ù§Ô∏è          True        True     False                     one                        keyword:one\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              good app for trading          True        True     False                    good                       keyword:good\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     best application in the world          True        True     False                   world                      keyword:world\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             it's the best program          True        True     False                 program                    keyword:program\n",
      "                                                                                                                                                                                                                                                                                                                                              What is your app? 10 minites Not open app.Not face save.Not login save Email your app.I understand your 100milion coustomer.after down 100 coustmer.not essy system.          True        True     False                    open                       keyword:open\n",
      "Almost perfect! Please make it more customizable. I prefer using tradingview + Binance in split screen rotated as it helps make quick/better decisions while looking at the chart and setting buy/sell orders. On binance app it takes extra clicks to go from the chart to buy/sell tab. K Line chart in buy/sell tab is useless as it's very small and nothing gets synced from the main chart. would love to have it all on the same tab horizontally. large chart+buy/sell tab below.I'm sure many would agree          True        True     False                     buy                        keyword:buy\n",
      "                                                                                                                                                                                                                                                                               When i take order there come a problem some time binance say insufficient margen i don't know what's the problem and when i a lot of time clicking clicking clicking then they take and order successful what's the problem Tell me          True        True     False                   order                      keyword:order\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    good app for treading trustful          True        True     False                    good                       keyword:good\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                         The last cloud mining product I purchased is not yet been released. with some stories I don't understand.          True        True     False                 product                    keyword:product\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          good app processing fast          True        True     False                    good                       keyword:good\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                  Add a payment method to your Google Account. Your payment information is only visible to Google.          True        True     False                  method                     keyword:method\n",
      "                                                                                                                                                                                                                                                                                                                               worst customer support.. they are just nonsense without any reason Or warning they restricted your account permanently.. you don't have choice to unban no one will listen to you..          True        True     False                customer                   keyword:customer\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Running a notebook-style script to load \"zerodha.csv\" from the working directory,\n",
    "# build a merged finance whitelist (FinRAD + a compact curated set), filter using\n",
    "# keyword whitelist + regex patterns, and save the filtered dataset.\n",
    "#\n",
    "# Output: saves filtered CSV to /mnt/data/zerodha_filtered.csv and displays a small sample and counts.\n",
    "#\n",
    "# Requirements: pandas, requests, nltk (nltk optional; code will fallback if not available).\n",
    "\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from typing import List, Set\n",
    "\n",
    "# ---------- Config ----------\n",
    "FINRAD_RAW_URL = \"https://raw.githubusercontent.com/sohomghosh/FinRAD_Financial_Readability_Assessment_Dataset/main/data_sample_1500.csv\"\n",
    "FINRAD_TOP_K = 500\n",
    "MIN_TOKEN_LENGTH = 3\n",
    "MIN_REVIEW_LEN = 10  # minimum characters for review to be considered\n",
    "FILENAME = \"binance_reviews_last5y.csv\"\n",
    "OUTPUT_PATH = FILENAME[:-4] + \"_filtered.csv\"\n",
    "\n",
    "COMMON_FIN_WORDS = {\n",
    "    \"buy\", \"sell\", \"trade\", \"order\", \"limit order\", \"market order\", \"stop loss\",\n",
    "    \"margin\", \"margin call\", \"intraday\", \"swing\", \"long\", \"short\",\n",
    "    \"stock\", \"share\", \"equity\", \"futures\", \"options\", \"mutual fund\", \"sip\", \"ipo\", \"etf\",\n",
    "    \"bond\", \"derivative\", \"portfolio\", \"broker\", \"brokerage\", \"commission\", \"fee\", \"tax\",\n",
    "    \"dividend\", \"profit\", \"loss\", \"pnl\", \"realized\", \"unrealized\", \"nse\", \"bse\", \"nifty\",\n",
    "    \"sensex\", \"ltp\", \"tick\", \"volume\", \"order id\", \"txn\", \"transaction\", \"txnid\",\n",
    "    \"settlement\", \"upi\", \"bank\", \"demat\", \"dp\", \"scrip\", \"circuit breaker\", \"selloff\",\n",
    "    \"panic\", \"panic-sell\", \"withdraw\", \"deposit\", \"portfolio value\", \"exit\", \"entry\",\n",
    "    \"brokerage\", \"tax-loss\", \"tax harvesting\", \"brokerage fee\", \"kyc\"\n",
    "}\n",
    "\n",
    "REGEX_PATTERNS = {\n",
    "    \"percent_value\": re.compile(r\"\\b\\d{1,3}(?:[.,]\\d+)?\\s?%\"),                        # 5% / 10.5 %\n",
    "    \"rupee_symbol_amount\": re.compile(r\"‚Çπ\\s?\\d[\\d,]*(?:\\.\\d+)?\"),                    # ‚Çπ1,234.56\n",
    "    \"rs_amount\": re.compile(r\"\\b(?:rs\\.?|inr)\\s?\\d[\\d,]*(?:\\.\\d+)?\\b\", re.I),         # rs 1200 / INR1200\n",
    "    \"exchange_tag\": re.compile(r\"\\b(?:NSE|BSE|NIFTY|SENSEX)\\b\", re.I),\n",
    "    \"order_txn\": re.compile(r\"\\b(?:order id|order#|ordernumber|txn id|transaction id|txnid)\\b\", re.I),\n",
    "    \"stop_loss_phrase\": re.compile(r\"\\bstop[- ]?loss\\b\", re.I),\n",
    "    \"margin_call_phrase\": re.compile(r\"\\bmargin call\\b\", re.I),\n",
    "    \"at_price_shorthand\": re.compile(r\"[@]\\s?\\d[\\d,]*(?:\\.\\d+)?\"),                    # '@ 450' or '@450'\n",
    "    \"percent_word\": re.compile(r\"\\bpercent\\b|\\bpercentage\\b\", re.I),\n",
    "    \"price_word\": re.compile(r\"\\bprice\\b|\\bclosing price\\b|\\bopen price\\b\", re.I),\n",
    "}\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def download_finrad_csv(raw_url: str, timeout=30):\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"python-requests/2.x\"}\n",
    "        r = requests.get(raw_url, headers=headers, timeout=timeout)\n",
    "        r.raise_for_status()\n",
    "        return r.content\n",
    "    except Exception as e:\n",
    "        print(f\"[warning] could not download FinRAD from {raw_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_finrad_df(raw_bytes: bytes):\n",
    "    try:\n",
    "        return pd.read_csv(io.BytesIO(raw_bytes), encoding=\"utf-8\", low_memory=False)\n",
    "    except Exception as e:\n",
    "        print(\"[warning] failed to parse FinRAD CSV:\", e)\n",
    "        return None\n",
    "\n",
    "# def choose_text_column(df: pd.DataFrame) -> str:\n",
    "#     preferred = [c for c in df.columns if c.lower() in {\"text\", \"sentence\", \"content\", \"sample\", \"excerpt\"}]\n",
    "#     if preferred:\n",
    "#         return preferred[0]\n",
    "#     # fallback: pick object dtype column with largest average length\n",
    "#     obj_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
    "#     if not obj_cols:\n",
    "#         return df.columns[0]\n",
    "#     avg_lens = {c: df[c].astype(str).str.len().mean() for c in obj_cols}\n",
    "#     return max(avg_lens, key=avg_lens.get)\n",
    "\n",
    "def extract_top_tokens_from_texts(texts: List[str], top_k=500, min_len=3, stopwords: Set[str]=None):\n",
    "    token_re = re.compile(r\"\\b[a-zA-Z]{%d,}\\b\" % min_len)\n",
    "    counter = Counter()\n",
    "    for t in texts:\n",
    "        if not isinstance(t, str):\n",
    "            continue\n",
    "        for m in token_re.findall(t):\n",
    "            token = m.lower()\n",
    "            if stopwords and token in stopwords:\n",
    "                continue\n",
    "            counter[token] += 1\n",
    "    most = [tok for tok, _ in counter.most_common(top_k)]\n",
    "    return most\n",
    "\n",
    "def compile_keyword_regex(words: List[str]) -> re.Pattern:\n",
    "    escaped = [re.escape(w) for w in sorted(set(words), key=len, reverse=True) if w.strip()]\n",
    "    if not escaped:\n",
    "        # fallback to a safe small pattern\n",
    "        return re.compile(r\"\\b(?:buy|sell|trade|stock|share|sip)\\b\", re.I)\n",
    "    pattern = r\"\\b(?:\" + \"|\".join(escaped) + r\")\\b\"\n",
    "    return re.compile(pattern, re.I)\n",
    "\n",
    "def filter_reviews_by_whitelist_and_regex(reviews_df: pd.DataFrame, text_col: str, keyword_pattern: re.Pattern, regex_patterns: dict, min_len: int = 10):\n",
    "    s = reviews_df[text_col].astype(str).fillna(\"\").str.strip()\n",
    "    length_ok = s.str.len() >= min_len\n",
    "    is_keyword = s.str.contains(keyword_pattern, na=False)\n",
    "\n",
    "    matched_any_regex = pd.Series(False, index=reviews_df.index)\n",
    "    matched_regex_keys = [[] for _ in range(len(reviews_df))]\n",
    "    for key, pat in regex_patterns.items():\n",
    "        found = s.str.contains(pat, na=False)\n",
    "        matched_any_regex = matched_any_regex | found\n",
    "        for idx in reviews_df.index[found]:\n",
    "            matched_regex_keys[idx] = matched_regex_keys[idx] + [key]\n",
    "\n",
    "    out = reviews_df.copy()\n",
    "    out[\"text_len\"] = s.str.len()\n",
    "    out[\"is_keyword\"] = is_keyword\n",
    "    out[\"is_regex\"] = matched_any_regex\n",
    "    out[\"matched_regexes\"] = [\",\".join(keys) if keys else \"\" for keys in matched_regex_keys]\n",
    "    def first_keyword_match(txt: str):\n",
    "        m = keyword_pattern.search(txt)\n",
    "        return m.group(0) if m else \"\"\n",
    "    out[\"matched_keyword_snippet\"] = s.apply(first_keyword_match)\n",
    "    out[\"finance_flag\"] = (out[\"is_keyword\"] | out[\"is_regex\"]) & length_ok\n",
    "\n",
    "    def reason_row(r):\n",
    "        if not r[\"finance_flag\"]:\n",
    "            return \"no_match_or_too_short\"\n",
    "        if r[\"is_keyword\"]:\n",
    "            return f\"keyword:{r['matched_keyword_snippet'] or 'match'}\"\n",
    "        if r[\"is_regex\"]:\n",
    "            return f\"regex:{r['matched_regexes']}\"\n",
    "        return \"matched\"\n",
    "    out[\"reason\"] = out.apply(reason_row, axis=1)\n",
    "    return out\n",
    "\n",
    "# ---------- Main execution ----------\n",
    "# 1) Check file exists\n",
    "if not os.path.exists(FILENAME):\n",
    "    raise FileNotFoundError(f\"'{FILENAME}' not found in working directory. Please ensure the file is present.\")\n",
    "\n",
    "# 2) Load zerodha.csv\n",
    "df = pd.read_csv(FILENAME, low_memory=False)\n",
    "print(f\"Loaded '{FILENAME}' with {len(df)} rows and columns: {list(df.columns)[:20]}\")\n",
    "\n",
    "# 3) Ensure 'content' column exists\n",
    "if \"content\" not in df.columns:\n",
    "    raise ValueError(\"Column 'content' not found in zerodha.csv. Please ensure your dataset has a 'content' column.\")\n",
    "\n",
    "# 4) Attempt to download FinRAD and extract tokens\n",
    "finrad_bytes = download_finrad_csv(FINRAD_RAW_URL)\n",
    "finrad_tokens = []\n",
    "if finrad_bytes:\n",
    "    df_fin = load_finrad_df(finrad_bytes)\n",
    "    if df_fin is not None:\n",
    "        text_col = \"terms\"\n",
    "        fin_texts = df_fin[text_col].astype(str).tolist()\n",
    "        # try to get stopwords\n",
    "        stopwords = set()\n",
    "        try:\n",
    "            import nltk\n",
    "            nltk.download('stopwords', quiet=True)\n",
    "            from nltk.corpus import stopwords as sw\n",
    "            stopwords = set(sw.words('english'))\n",
    "        except Exception:\n",
    "            stopwords = {\"the\", \"and\", \"for\", \"with\", \"that\", \"this\", \"are\", \"was\", \"from\", \"have\", \"has\"}\n",
    "        finrad_tokens = extract_top_tokens_from_texts(fin_texts, top_k=FINRAD_TOP_K, min_len=MIN_TOKEN_LENGTH, stopwords=stopwords)\n",
    "        print(f\"Extracted {len(finrad_tokens)} tokens from FinRAD (top {FINRAD_TOP_K}).\")\n",
    "    else:\n",
    "        print(\"Could not parse FinRAD CSV; continuing with curated common words only.\")\n",
    "else:\n",
    "    print(\"FinRAD download failed; continuing with curated common words only.\")\n",
    "\n",
    "# 5) Merge whitelist\n",
    "merged = set(w.lower() for w in COMMON_FIN_WORDS)\n",
    "merged.update(finrad_tokens)\n",
    "merged_list = sorted(merged)\n",
    "print(f\"Merged whitelist size: {len(merged_list)} (including curated common words and FinRAD-derived tokens)\")\n",
    "\n",
    "# 6) Compile keyword regex\n",
    "keyword_re = compile_keyword_regex(merged_list)\n",
    "\n",
    "# 7) Apply filter on 'content' column\n",
    "filtered_df = filter_reviews_by_whitelist_and_regex(df, text_col=\"content\", keyword_pattern=keyword_re, regex_patterns=REGEX_PATTERNS, min_len=MIN_REVIEW_LEN)\n",
    "\n",
    "# 8) Save filtered dataset (only rows where finance_flag is True)\n",
    "finance_rows = filtered_df[filtered_df[\"finance_flag\"]].copy()\n",
    "finance_rows.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"Filtered dataset saved to: {OUTPUT_PATH}\")\n",
    "print(f\"Total rows: {len(df)}, Finance-related rows kept: {len(finance_rows)} ({len(finance_rows)/len(df)*100:.2f}%)\")\n",
    "\n",
    "# 9) Display a small sample of kept rows and some columns for explainability\n",
    "display_cols = [\"content\", \"finance_flag\", \"is_keyword\", \"is_regex\", \"matched_keyword_snippet\", \"matched_regexes\", \"reason\"]\n",
    "sample_display = finance_rows[display_cols].head(20)\n",
    "print(sample_display.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb9fd0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165185\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_df['content'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0edafbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19063, 14)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "031b8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "NEGATIVE_WORDS = {\n",
    "    # app / UI / UX\n",
    "    \"app\", \"application\", \"ui\", \"ux\", \"interface\", \"layout\", \"theme\", \"dark mode\", \"color\", \"design\",\n",
    "    \"button\", \"menu\", \"screen\", \"screen freeze\", \"freeze\", \"frozen\", \"render\", \"scroll\", \"tap\", \"click\",\n",
    "    \"slow\", \"lag\", \"lagging\", \"loading\", \"load\", \"responsive\", \"unresponsive\", \"crash\", \"crashes\", \"crashed\",\n",
    "    \"bug\", \"bugs\", \"glitch\", \"glitches\", \"error\", \"errors\", \"exception\",\n",
    "    # login / auth / registration / account access\n",
    "    \"login\", \"logout\", \"signin\", \"sign in\", \"signup\", \"sign up\", \"register\", \"registration\", \"password\",\n",
    "    \"forgot password\", \"otp\", \"two-factor\", \"2fa\", \"mfa\", \"biometric\", \"fingerprint\", \"faceid\",\n",
    "    \"pin\", \"pincode\", \"session expired\", \"session\", \"token\", \"auth\", \"authenticate\",\n",
    "    # install / update / store / rating\n",
    "    \"install\", \"uninstall\", \"update\", \"updated\", \"version\", \"play store\", \"app store\", \"rating\", \"stars\",\n",
    "    # notifications & permissions\n",
    "    \"notification\", \"notifications\", \"permission\", \"permissions\", \"push\", \"push notification\",\n",
    "    # support / contact / help (often app/ops)\n",
    "    \"support\", \"customer support\", \"help\", \"contact\", \"ticket\",\n",
    "    # UI-specific shorthand\n",
    "    \"hamburger\", \"toolbar\", \"popup\", \"dialog\", \"modal\"\n",
    "}\n",
    "\n",
    "def compile_phrase_regex(words):\n",
    "    escaped = [re.escape(w) for w in sorted(set(words), key=len, reverse=True) if w.strip()]\n",
    "    if not escaped:\n",
    "        return re.compile(r\"$^\", re.I)\n",
    "    pattern = r\"\\b(?:\" + \"|\".join(escaped) + r\")\\b\"\n",
    "    return re.compile(pattern, re.I)\n",
    "\n",
    "NEGATIVE_REGEX = compile_phrase_regex(NEGATIVE_WORDS)\n",
    "\n",
    "def negative_filter(finance_rows, text_col=\"content\", drop=True):\n",
    "    \"\"\"\n",
    "    finance_rows: pandas.DataFrame containing filtered (finance-related) reviews.\n",
    "    text_col: column name with review text (default 'content').\n",
    "    drop: if True, returns DataFrame with negative-flagged rows removed.\n",
    "          if False, returns DataFrame with negative_flag and negative_match_snippet columns added.\n",
    "    \"\"\"\n",
    "    s = finance_rows[text_col].astype(str).fillna(\"\")\n",
    "    negative_matches = s.str.contains(NEGATIVE_REGEX, na=False)\n",
    "    out = finance_rows.copy()\n",
    "    out[\"negative_flag\"] = negative_matches\n",
    "    # snippet for explainability\n",
    "    def _snippet(txt):\n",
    "        m = NEGATIVE_REGEX.search(txt)\n",
    "        return m.group(0) if m else \"\"\n",
    "    out[\"negative_match_snippet\"] = out[text_col].apply(_snippet)\n",
    "    if drop:\n",
    "        return out[~out[\"negative_flag\"]].reset_index(drop=True)\n",
    "    else:\n",
    "        return out.reset_index(drop=True)\n",
    "\n",
    "# Usage:\n",
    "# finance_rows_filtered = negative_filter(finance_rows, text_col=\"content\", drop=True)\n",
    "# or to keep & flag:\n",
    "# finance_rows_flagged = negative_filter(finance_rows, text_col=\"content\", drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "298b3efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned finance-only reviews (UI/login removed): 9359 rows -> binance_reviews_last5y_filtered_no_ui.csv\n"
     ]
    }
   ],
   "source": [
    "# Assumes `negative_filter` function and `finance_rows` DataFrame are already defined (from previous step).\n",
    "# This snippet runs negative filtering, saves the dropped-version (clean) and a flagged-version (kept+flags).\n",
    "\n",
    "# 1) Produce cleaned DataFrame (UI/login/etc. rows removed)\n",
    "final_df = negative_filter(finance_rows, text_col=\"content\", drop=True)\n",
    "\n",
    "# 2) Save cleaned results to CSV (and optionally parquet)\n",
    "final_csv_path = FILENAME[:-4] + \"_filtered_no_ui.csv\"\n",
    "final_df.to_csv(final_csv_path, index=False)\n",
    "# optional: faster/binary format\n",
    "try:\n",
    "    final_df.to_parquet(\"zerodha_finance_filtered_no_ui.parquet\", index=False)\n",
    "except Exception:\n",
    "    # parquet optional ‚Äî skip if pyarrow/fastparquet not installed\n",
    "    pass\n",
    "\n",
    "print(f\"Saved cleaned finance-only reviews (UI/login removed): {len(final_df)} rows -> {final_csv_path}\")\n",
    "\n",
    "# # 3) If you want a flagged file (keeps UI/login rows but marks them), produce & save that too\n",
    "# flagged_df = negative_filter(finance_rows, text_col=\"content\", drop=False)\n",
    "# flagged_csv_path = \"zerodha_finance_filtered_flagged_ui.csv\"\n",
    "# flagged_df.to_csv(flagged_csv_path, index=False)\n",
    "# print(f\"Saved finance reviews with negative flags: {len(flagged_df)} rows -> {flagged_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "137635b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae0e7ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(final_df['content'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592eaa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin-stress-reviews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
